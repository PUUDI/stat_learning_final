{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 >Credit Card Approval Prediction Using Sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Content<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Response-Variable\" data-toc-modified-id=\"Response-Variable-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Response Variable</a></span></li><li><span><a href=\"#Features\" data-toc-modified-id=\"Features-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Binary-Features\" data-toc-modified-id=\"Binary-Features-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Binary Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gender\" data-toc-modified-id=\"Gender-1.2.1.1\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>Gender</a></span></li><li><span><a href=\"#Having-a-car-or-not\" data-toc-modified-id=\"Having-a-car-or-not-1.2.1.2\"><span class=\"toc-item-num\">1.2.1.2&nbsp;&nbsp;</span>Having a car or not</a></span></li><li><span><a href=\"#Having-house-reality-or-not\" data-toc-modified-id=\"Having-house-reality-or-not-1.2.1.3\"><span class=\"toc-item-num\">1.2.1.3&nbsp;&nbsp;</span>Having house reality or not</a></span></li><li><span><a href=\"#Having-a-phone-or-not\" data-toc-modified-id=\"Having-a-phone-or-not-1.2.1.4\"><span class=\"toc-item-num\">1.2.1.4&nbsp;&nbsp;</span>Having a phone or not</a></span></li><li><span><a href=\"#Having-an-email-or-not\" data-toc-modified-id=\"Having-an-email-or-not-1.2.1.5\"><span class=\"toc-item-num\">1.2.1.5&nbsp;&nbsp;</span>Having an email or not</a></span></li><li><span><a href=\"#Having-a-Work-Phone-or-not\" data-toc-modified-id=\"Having-a-Work-Phone-or-not-1.2.1.6\"><span class=\"toc-item-num\">1.2.1.6&nbsp;&nbsp;</span>Having a Work Phone or not</a></span></li></ul></li><li><span><a href=\"#Continuous-Variables\" data-toc-modified-id=\"Continuous-Variables-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Continuous Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Children-Numbers\" data-toc-modified-id=\"Children-Numbers-1.2.2.1\"><span class=\"toc-item-num\">1.2.2.1&nbsp;&nbsp;</span>Children Numbers</a></span></li><li><span><a href=\"#Annual-Income\" data-toc-modified-id=\"Annual-Income-1.2.2.2\"><span class=\"toc-item-num\">1.2.2.2&nbsp;&nbsp;</span>Annual Income</a></span></li><li><span><a href=\"#Age\" data-toc-modified-id=\"Age-1.2.2.3\"><span class=\"toc-item-num\">1.2.2.3&nbsp;&nbsp;</span>Age</a></span></li><li><span><a href=\"#Working-Years\" data-toc-modified-id=\"Working-Years-1.2.2.4\"><span class=\"toc-item-num\">1.2.2.4&nbsp;&nbsp;</span>Working Years</a></span></li><li><span><a href=\"#Famliy-Size\" data-toc-modified-id=\"Famliy-Size-1.2.2.5\"><span class=\"toc-item-num\">1.2.2.5&nbsp;&nbsp;</span>Famliy Size</a></span></li></ul></li><li><span><a href=\"#Categorical-Features\" data-toc-modified-id=\"Categorical-Features-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Categorical Features</a></span><ul class=\"toc-item\"><li><span><a href=\"#Income-Type\" data-toc-modified-id=\"Income-Type-1.2.3.1\"><span class=\"toc-item-num\">1.2.3.1&nbsp;&nbsp;</span>Income Type</a></span></li><li><span><a href=\"#Occupation-Type\" data-toc-modified-id=\"Occupation-Type-1.2.3.2\"><span class=\"toc-item-num\">1.2.3.2&nbsp;&nbsp;</span>Occupation Type</a></span></li><li><span><a href=\"#House-Type\" data-toc-modified-id=\"House-Type-1.2.3.3\"><span class=\"toc-item-num\">1.2.3.3&nbsp;&nbsp;</span>House Type</a></span></li><li><span><a href=\"#Education\" data-toc-modified-id=\"Education-1.2.3.4\"><span class=\"toc-item-num\">1.2.3.4&nbsp;&nbsp;</span>Education</a></span></li><li><span><a href=\"#Marriage-Condition\" data-toc-modified-id=\"Marriage-Condition-1.2.3.5\"><span class=\"toc-item-num\">1.2.3.5&nbsp;&nbsp;</span>Marriage Condition</a></span></li></ul></li></ul></li><li><span><a href=\"#IV、WOE：Concept-and-Application\" data-toc-modified-id=\"IV、WOE：Concept-and-Application-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>IV、WOE：Concept and Application</a></span></li></ul></li><li><span><a href=\"#Algorithms\" data-toc-modified-id=\"Algorithms-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Algorithms</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Decision Tree</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#SVM\" data-toc-modified-id=\"SVM-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>SVM</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>LightGBM</a></span></li><li><span><a href=\"#Xgboost\" data-toc-modified-id=\"Xgboost-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Xgboost</a></span></li><li><span><a href=\"#Keras-Neural-Networks\" data-toc-modified-id=\"Keras-Neural-Networks-2.7\"><span class=\"toc-item-num\">2.7&nbsp;&nbsp;</span>Keras Neural Networks</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMClassifier\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"application_record.csv\", encoding = 'utf-8') \n",
    "record = pd.read_csv(\"credit_record.csv\", encoding = 'utf-8')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all users' account open month.\n",
    "begin_month=pd.DataFrame(record.groupby([\"ID\"])[\"MONTHS_BALANCE\"].agg(min))\n",
    "begin_month=begin_month.rename(columns={'MONTHS_BALANCE':'begin_month'}) \n",
    "new_data=pd.merge(data,begin_month,how=\"left\",on=\"ID\") #merge to record data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally, users in risk should be in 3%, thus I choose users who overdue for more than 60 days as target risk users. Those samples are marked as '1', else are '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record['dep_value'] = None\n",
    "record['dep_value'][record['STATUS'] =='2']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='3']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='4']='Yes' \n",
    "record['dep_value'][record['STATUS'] =='5']='Yes' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpunt=record.groupby('ID').count()\n",
    "cpunt['dep_value'][cpunt['dep_value'] > 0]='Yes' \n",
    "cpunt['dep_value'][cpunt['dep_value'] == 0]='No' \n",
    "cpunt = cpunt[['dep_value']]\n",
    "new_data=pd.merge(new_data,cpunt,how='inner',on='ID')\n",
    "new_data['target']=new_data['dep_value']\n",
    "new_data.loc[new_data['target']=='Yes','target']=1\n",
    "new_data.loc[new_data['target']=='No','target']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cpunt['dep_value'].value_counts())\n",
    "cpunt['dep_value'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ rename "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.rename(columns={'CODE_GENDER':'Gender','FLAG_OWN_CAR':'Car','FLAG_OWN_REALTY':'Reality',\n",
    "                         'CNT_CHILDREN':'ChldNo','AMT_INCOME_TOTAL':'inc',\n",
    "                         'NAME_EDUCATION_TYPE':'edutp','NAME_FAMILY_STATUS':'famtp',\n",
    "                        'NAME_HOUSING_TYPE':'houtp','FLAG_EMAIL':'email',\n",
    "                         'NAME_INCOME_TYPE':'inctp','FLAG_WORK_PHONE':'wkphone',\n",
    "                         'FLAG_PHONE':'phone','CNT_FAM_MEMBERS':'famsize',\n",
    "                        'OCCUPATION_TYPE':'occyp'\n",
    "                        },inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.dropna()\n",
    "new_data = new_data.mask(new_data == 'NULL').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivtable=pd.DataFrame(new_data.columns,columns=['variable'])\n",
    "ivtable['IV']=None\n",
    "namelist = ['FLAG_MOBIL','begin_month','dep_value','target','ID']\n",
    "\n",
    "for i in namelist:\n",
    "    ivtable.drop(ivtable[ivtable['variable'] == i].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Define `calc_iv` function to [calculate](https://www.kaggle.com/puremath86/iv-woe-starter-for-python) Information Value and WOE Value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate information value\n",
    "def calc_iv(df, feature, target, pr=False):\n",
    "    lst = []\n",
    "    df[feature] = df[feature].fillna(\"NULL\")\n",
    "\n",
    "    for i in range(df[feature].nunique()):\n",
    "        val = list(df[feature].unique())[i]\n",
    "        lst.append([feature,                                                        # Variable\n",
    "                    val,                                                            # Value\n",
    "                    df[df[feature] == val].count()[feature],                        # All\n",
    "                    df[(df[feature] == val) & (df[target] == 0)].count()[feature],  # Good (think: Fraud == 0)\n",
    "                    df[(df[feature] == val) & (df[target] == 1)].count()[feature]]) # Bad (think: Fraud == 1)\n",
    "\n",
    "    data = pd.DataFrame(lst, columns=['Variable', 'Value', 'All', 'Good', 'Bad'])\n",
    "    data['Share'] = data['All'] / data['All'].sum()\n",
    "    data['Bad Rate'] = data['Bad'] / data['All']\n",
    "    data['Distribution Good'] = (data['All'] - data['Bad']) / (data['All'].sum() - data['Bad'].sum())\n",
    "    data['Distribution Bad'] = data['Bad'] / data['Bad'].sum()\n",
    "    data['WoE'] = np.log(data['Distribution Good'] / data['Distribution Bad'])\n",
    "    \n",
    "    data = data.replace({'WoE': {np.inf: 0, -np.inf: 0}})\n",
    "\n",
    "    data['IV'] = data['WoE'] * (data['Distribution Good'] - data['Distribution Bad'])\n",
    "\n",
    "    data = data.sort_values(by=['Variable', 'Value'], ascending=[True, True])\n",
    "    data.index = range(len(data.index))\n",
    "\n",
    "    if pr:\n",
    "        print(data)\n",
    "        print('IV = ', data['IV'].sum())\n",
    "\n",
    "    iv = data['IV'].sum()\n",
    "    print('This variable\\'s IV is:',iv)\n",
    "    print(df[feature].value_counts())\n",
    "    return iv, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dummy(df, feature,rank=0):\n",
    "    pos = pd.get_dummies(df[feature], prefix=feature)\n",
    "    mode = df[feature].value_counts().index[rank]\n",
    "    biggest = feature + '_' + str(mode)\n",
    "    pos.drop([biggest],axis=1,inplace=True)\n",
    "    df.drop([feature],axis=1,inplace=True)\n",
    "    df=df.join(pos)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(df, col, binsnum, labels, qcut = False):\n",
    "    if qcut:\n",
    "        localdf = pd.qcut(df[col], q = binsnum, labels = labels) # quantile cut\n",
    "    else:\n",
    "        localdf = pd.cut(df[col], bins = binsnum, labels = labels) # equal-length cut\n",
    "        \n",
    "    localdf = pd.DataFrame(localdf)\n",
    "    name = 'gp' + '_' + col\n",
    "    localdf[name] = localdf[col]\n",
    "    df = df.join(localdf[name])\n",
    "    df[name] = df[name].astype(object)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Gender'] = new_data['Gender'].replace(['F','M'],[0,1])\n",
    "print(new_data['Gender'].value_counts())\n",
    "iv, data = calc_iv(new_data,'Gender','target')\n",
    "ivtable.loc[ivtable['variable']=='Gender','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having a car or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Car'] = new_data['Car'].replace(['N','Y'],[0,1])\n",
    "print(new_data['Car'].value_counts())\n",
    "iv, data=calc_iv(new_data,'Car','target')\n",
    "ivtable.loc[ivtable['variable']=='Car','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having house reality or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Reality'] = new_data['Reality'].replace(['N','Y'],[0,1])\n",
    "print(new_data['Reality'].value_counts())\n",
    "iv, data=calc_iv(new_data,'Reality','target')\n",
    "ivtable.loc[ivtable['variable']=='Reality','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having a phone or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['phone']=new_data['phone'].astype(str)\n",
    "print(new_data['phone'].value_counts(normalize=True,sort=False))\n",
    "new_data.drop(new_data[new_data['phone'] == 'nan' ].index, inplace=True)\n",
    "iv, data=calc_iv(new_data,'phone','target')\n",
    "ivtable.loc[ivtable['variable']=='phone','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having an email or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['email'].value_counts(normalize=True,sort=False))\n",
    "new_data['email']=new_data['email'].astype(str)\n",
    "iv, data=calc_iv(new_data,'email','target')\n",
    "ivtable.loc[ivtable['variable']=='email','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having a Work Phone or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['wkphone']=new_data['wkphone'].astype(str)\n",
    "iv, data = calc_iv(new_data,'wkphone','target')\n",
    "new_data.drop(new_data[new_data['wkphone'] == 'nan' ].index, inplace=True)\n",
    "ivtable.loc[ivtable['variable']=='wkphone','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Variables\n",
    "\n",
    "#### Children Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['ChldNo'] >= 2,'ChldNo']='2More'\n",
    "print(new_data['ChldNo'].value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'ChldNo','target')\n",
    "ivtable.loc[ivtable['variable']=='ChldNo','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'ChldNo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Annual Income\n",
    "bins the data based on sample quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['inc']=new_data['inc'].astype(object)\n",
    "new_data['inc'] = new_data['inc']/10000 \n",
    "print(new_data['inc'].value_counts(bins=10,sort=False))\n",
    "new_data['inc'].plot(kind='hist',bins=50,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'inc', 3, [\"low\",\"medium\", \"high\"], qcut = True)\n",
    "iv, data = calc_iv(new_data,'gp_inc','target')\n",
    "ivtable.loc[ivtable['variable']=='inc','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_inc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age\n",
    "Bucketing Continuous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Age']=-(new_data['DAYS_BIRTH'])//365\t\n",
    "print(new_data['Age'].value_counts(bins=10,normalize=True,sort=False))\n",
    "new_data['Age'].plot(kind='hist',bins=20,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'Age',5, [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\n",
    "iv, data = calc_iv(new_data,'gp_Age','target')\n",
    "ivtable.loc[ivtable['variable']=='DAYS_BIRTH','IV'] = iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working Years\n",
    "+ Equal-length Bucketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['worktm']=-(new_data['DAYS_EMPLOYED'])//365\t\n",
    "new_data[new_data['worktm']<0] = np.nan # replace by na\n",
    "new_data['DAYS_EMPLOYED']\n",
    "new_data['worktm'].fillna(new_data['worktm'].mean(),inplace=True) #replace na by mean\n",
    "new_data['worktm'].plot(kind='hist',bins=20,density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = get_category(new_data,'worktm',5, [\"lowest\",\"low\",\"medium\",\"high\",\"highest\"])\n",
    "iv, data=calc_iv(new_data,'gp_worktm','target')\n",
    "ivtable.loc[ivtable['variable']=='DAYS_EMPLOYED','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'gp_worktm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Famliy Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['famsize'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['famsize']=new_data['famsize'].astype(int)\n",
    "new_data['famsizegp']=new_data['famsize']\n",
    "new_data['famsizegp']=new_data['famsizegp'].astype(object)\n",
    "new_data.loc[new_data['famsizegp']>=3,'famsizegp']='3more'\n",
    "iv, data=calc_iv(new_data,'famsizegp','target')\n",
    "ivtable.loc[ivtable['variable']=='famsize','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'famsizegp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Income Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_data['inctp'].value_counts(sort=False))\n",
    "print(new_data['inctp'].value_counts(normalize=True,sort=False))\n",
    "new_data.loc[new_data['inctp']=='Pensioner','inctp']='State servant'\n",
    "new_data.loc[new_data['inctp']=='Student','inctp']='State servant'\n",
    "iv, data=calc_iv(new_data,'inctp','target')\n",
    "ivtable.loc[ivtable['variable']=='inctp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'inctp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Occupation Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[(new_data['occyp']=='Cleaning staff') | (new_data['occyp']=='Cooking staff') | (new_data['occyp']=='Drivers') | (new_data['occyp']=='Laborers') | (new_data['occyp']=='Low-skill Laborers') | (new_data['occyp']=='Security staff') | (new_data['occyp']=='Waiters/barmen staff'),'occyp']='Laborwk'\n",
    "new_data.loc[(new_data['occyp']=='Accountants') | (new_data['occyp']=='Core staff') | (new_data['occyp']=='HR staff') | (new_data['occyp']=='Medicine staff') | (new_data['occyp']=='Private service staff') | (new_data['occyp']=='Realty agents') | (new_data['occyp']=='Sales staff') | (new_data['occyp']=='Secretaries'),'occyp']='officewk'\n",
    "new_data.loc[(new_data['occyp']=='Managers') | (new_data['occyp']=='High skill tech staff') | (new_data['occyp']=='IT staff'),'occyp']='hightecwk'\n",
    "print(new_data['occyp'].value_counts())\n",
    "iv, data=calc_iv(new_data,'occyp','target')\n",
    "ivtable.loc[ivtable['variable']=='occyp','IV']=iv\n",
    "data.head()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'occyp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### House Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'houtp','target')\n",
    "ivtable.loc[ivtable['variable']=='houtp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'houtp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.loc[new_data['edutp']=='Academic degree','edutp']='Higher education'\n",
    "iv, data=calc_iv(new_data,'edutp','target')\n",
    "ivtable.loc[ivtable['variable']=='edutp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'edutp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Marriage Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_data['famtp'].value_counts(normalize=True,sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv, data=calc_iv(new_data,'famtp','target')\n",
    "ivtable.loc[ivtable['variable']=='famtp','IV']=iv\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = convert_dummy(new_data,'famtp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV、WOE：Concept and Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight of Evidence(WoE):  \n",
    "\n",
    "$$wo{e_i} = \\ln {{{P_{yi}}} \\over {{P_{ni}}}} = \\ln {{{y_i}/{y_s}} \\over {{n_i}/{n_s}}}$$\n",
    "$wo{e_i}$ is the I category's WOE value. ${{P_{yi}}}$ is the proportion of the positive samples in this category to all positive samples.   ${{P_{ni}}}$ is the ratio of negative samples (${{n_i}}$) in this class to all negative samples (${{n_s}}$).\n",
    "\n",
    "Information Value (IV):  \n",
    "$$I{V_i} = ({P_{yi}} - {P_{ni}}) \\times wo{e_i}$$  \n",
    "The IV values of the various types are the difference between the conditional positive rate and the conditional negative rate multiplied by the WOE value of the variable. The total IV value of the variable can be understood as the weighted sum of the conditional positive rate and the conditional negative rate difference:\n",
    "$$IV = \\sum\\limits_i^n {I{V_i}} $$  \n",
    "\n",
    "The IV value measures the variable's ability to predict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship between IV value and predictive power\n",
    "\n",
    "| IV| Ability to predict | \n",
    "|:------|:------:| \n",
    "| <0.02 | Almost no predictive power | \n",
    "|0.02~0.1 |weak predictive power|\n",
    "|0.1~0.3|Moderate predictive power|\n",
    "|0.3~0.5|Strong predictive power|\n",
    "|>0.5|Predictive power is too strong, need to check variables| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivtable=ivtable.sort_values(by='IV',ascending=False)\n",
    "ivtable.loc[ivtable['variable']=='DAYS_BIRTH','variable']='agegp'\n",
    "ivtable.loc[ivtable['variable']=='DAYS_EMPLOYED','variable']='worktmgp'\n",
    "ivtable.loc[ivtable['variable']=='inc','variable']='incgp'\n",
    "ivtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = new_data['target']\n",
    "X = new_data[['Gender','Reality','ChldNo_1', 'ChldNo_2More','wkphone',\n",
    "              'gp_Age_high', 'gp_Age_highest', 'gp_Age_low',\n",
    "       'gp_Age_lowest','gp_worktm_high', 'gp_worktm_highest',\n",
    "       'gp_worktm_low', 'gp_worktm_medium','occyp_hightecwk', \n",
    "              'occyp_officewk','famsizegp_1', 'famsizegp_3more',\n",
    "       'houtp_Co-op apartment', 'houtp_Municipal apartment',\n",
    "       'houtp_Office apartment', 'houtp_Rented apartment',\n",
    "       'houtp_With parents','edutp_Higher education',\n",
    "       'edutp_Incomplete higher', 'edutp_Lower secondary','famtp_Civil marriage',\n",
    "       'famtp_Separated','famtp_Single / not married','famtp_Widow']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Using Synthetic Minority Over-Sampling Technique(`SMOTE`) to overcome sample imbalance problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.astype('int')\n",
    "X_balance,Y_balance = SMOTE().fit_sample(X,Y)\n",
    "X_balance = pd.DataFrame(X_balance, columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ After over sampling, the number between 1 and 0 is balanced. It can be seen from the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_balance,Y_balance, \n",
    "                                                    stratify=Y_balance, test_size=0.3,\n",
    "                                                    random_state = 10086)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression   \n",
    "\n",
    "$$\\log ({p \\over {1 - p}}) = {\\beta _0} + {\\beta _1}{x_1} +  \\cdot  \\cdot  \\cdot  + {\\beta _q}{x_q}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=0.8,\n",
    "                           random_state=0,\n",
    "                           solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "sns.set_style('white') \n",
    "class_names = ['0','1']\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes= class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: Logistic Regression')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=12,\n",
    "                               min_samples_split=8,\n",
    "                               random_state=1024)\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: CART')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest   \n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"https://d1rwhvwstyk9gu.cloudfront.net/2019/03/Random-Forest-Algorithm.jpg\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">Random Forest</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=250,\n",
    "                              max_depth=12,\n",
    "                              min_samples_leaf=16\n",
    "                              )\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: Ramdom Forests')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "\n",
    "<center>\n",
    "    <img style=\"border-radius: 0.3125em;\n",
    "    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);\" \n",
    "    src=\"https://i.loli.net/2019/11/13/fryWG5al7OPHDiA.gif\">\n",
    "    <br>\n",
    "    <div style=\"color:orange; border-bottom: 1px solid #d9d9d9;\n",
    "    display: inline-block;\n",
    "    color: #999;\n",
    "    padding: 2px;\">Support Vector Machine</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.SVC(C = 0.8,\n",
    "                kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix(y_test,y_predict),\n",
    "                      classes=class_names, normalize = True, \n",
    "                      title='Normalized Confusion Matrix: SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMClassifier(num_leaves=31,\n",
    "                       max_depth=8, \n",
    "                       learning_rate=0.02,\n",
    "                       n_estimators=250,\n",
    "                       subsample = 0.8,\n",
    "                       colsample_bytree =0.8\n",
    "                      )\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing important features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importance(classifer, x_train, point_size = 25):\n",
    "    '''plot feature importance'''\n",
    "    values = sorted(zip(x_train.columns, classifer.feature_importances_), key = lambda x: x[1] * -1)\n",
    "    imp = pd.DataFrame(values,columns = [\"Name\", \"Score\"])\n",
    "    imp.sort_values(by = 'Score',inplace = True)\n",
    "    sns.scatterplot(x = 'Score',y='Name', linewidth = 0,\n",
    "                data = imp,s = point_size, color='red').set(\n",
    "    xlabel='importance', \n",
    "    ylabel='features')\n",
    "    \n",
    "plot_importance(model, X_train,20)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.booster_.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=12,\n",
    "                      n_estimators=250,\n",
    "                      min_child_weight=8, \n",
    "                      subsample=0.8, \n",
    "                      learning_rate =0.02,    \n",
    "                      seed=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print('Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(model, X_train, 20)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostClassifier(iterations=250,\n",
    "                           learning_rate=0.2,\n",
    "                           od_type='Iter',\n",
    "                           verbose=25,\n",
    "                           depth=16,\n",
    "                           random_seed=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print('CatBoost Accuracy Score is {:.5}'.format(accuracy_score(y_test, y_predict)))\n",
    "print(pd.DataFrame(confusion_matrix(y_test,y_predict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3 > Please upvote it if you like it! </font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
