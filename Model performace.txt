Logistic Regression with parameters
accuracy  :  0.681411066673444
precision  :  0.6640920143345703
recall  :  0.7328585033628738
Time elapsed:  5.414385795593262


Decision Tree Classifier
accuracy  :  0.8003785635925235
precision  :  0.7450022019258055
recall  :  0.9138546629650135
Time elapsed:  0.9997541904449463


Support Vector Machine
accuracy  :  0.6625393383317013
precision  :  0.6556401205878338
recall  :  0.6846211665056959
Time elapsed:  206.37223482131958


Random Forest
accuracy  :  0.9053995300102367
precision  :  0.8733735789401503
recall  :  0.9463438092274619
Time elapsed:  26.668754816055298


Logistic Regression
accuracy  :  0.6813290658810389
precision  :  0.6639782565751251
recall  :  0.7328585033628738
Time elapsed:  1.384354591369629


Linear Discriminant Analysis
accuracy  :  0.6815746979755296
precision  :  0.6630198720993479
recall  :  0.7376166364257225
Time elapsed:  2.137072801589966


Gradient Boosting
accuracy  :  0.7947995137851209
precision  :  0.7693093023211783
recall  :  0.8414904407634458
Time elapsed:  29.954367637634277


Light Gradient Boosting
accuracy  :  0.8470652232821658
precision  :  0.8204142334688992
recall  :  0.8879281383566976
Time elapsed:  10.666882753372192

X Gradient Bossting
accuracy  :  0.874797413272212
precision  :  0.8626283639836079
recall  :  0.8912104594602968
Time elapsed:  69.60619020462036

We choosed XGBoosting and Random Forest classifier from the initial performace and went onto perform Grid search to find the best parameters

After best params selection through Grid Search

Gradient Boosting 
accuracy  :  0.7865130240215868
precision  :  0.7276244727209809
recall  :  0.9153291278888858
Time elapsed:  3.2356746196746826

Random Forest
accuracy  :  0.9060563442390572
precision  :  0.8780321607687588
recall  :  0.943060814606174
Time elapsed:  682.2166404724121